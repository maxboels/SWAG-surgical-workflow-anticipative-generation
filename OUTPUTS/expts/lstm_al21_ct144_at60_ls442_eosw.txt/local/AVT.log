[2024-05-31 07:43:58,634][func.train][INFO] - Dist info:
[2024-05-31 07:43:58,635][func.train][INFO] - torch version: 2.2.2+cu121
[2024-05-31 07:43:58,636][func.train][INFO] - torchvision version: 0.17.2+cu121
[2024-05-31 07:43:58,636][func.train][INFO] - hydra version: 1.3.2
[2024-05-31 07:43:58,640][func.train][INFO] - Loading data
[2024-05-31 07:43:58,641][func.train][INFO] - Loading datasets
[2024-05-31 07:43:59,041][func.train][INFO] - [SELECT DATASET] ALL loaded dataframe in 0m 0s
[2024-05-31 07:43:59,041][func.train][INFO] - [SELECT DATASET] ALL loaded dataframe: (83243, 4)
[2024-05-31 07:43:59,052][func.train][INFO] - [SELECT DATASET] labels are already starting from 0
[2024-05-31 07:43:59,065][func.train][INFO] - [SELECT DATASET] ALL unique classes: [0 1 2 3 4 5 6]
[2024-05-31 07:43:59,075][func.train][INFO] - [SELECT DATASET] aLL dataframe (head):                                           image_path  video_idx frame_idx class
0  /nfs/home/yangliu/dataset/AutoLaparo_Task1/Aut...          1         1     1
1  /nfs/home/yangliu/dataset/AutoLaparo_Task1/Aut...          1         2     1
2  /nfs/home/yangliu/dataset/AutoLaparo_Task1/Aut...          1         3     1
3  /nfs/home/yangliu/dataset/AutoLaparo_Task1/Aut...          1         4     1
4  /nfs/home/yangliu/dataset/AutoLaparo_Task1/Aut...          1         5     1
[2024-05-31 07:43:59,085][func.train][INFO] - [SELECT DATASET] ALL dataframe (tail):                                               image_path  ...  class
83238  /nfs/home/yangliu/dataset/AutoLaparo_Task1/Aut...  ...      6
83239  /nfs/home/yangliu/dataset/AutoLaparo_Task1/Aut...  ...      6
83240  /nfs/home/yangliu/dataset/AutoLaparo_Task1/Aut...  ...      6
83241  /nfs/home/yangliu/dataset/AutoLaparo_Task1/Aut...  ...      6
83242  /nfs/home/yangliu/dataset/AutoLaparo_Task1/Aut...  ...      6

[5 rows x 4 columns]
[2024-05-31 07:43:59,086][func.train][INFO] - [DATASET] params: {'debug': False, 'dataset_name': 'autolaparo21', 'reduc_feats_folder': 'train_targets_x_mp/', 'num_classes': 7, 'num_next_labels': 6, 'last_seg_class': 7, 'predict_next_phase': True, 'get_target_feats': False, 'replace_current_with_next_class': False}
[2024-05-31 07:43:59,140][func.train][INFO] - [DATASET] df unique videos: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21]
[2024-05-31 07:43:59,140][func.train][INFO] - [DATASET] split: train video_indices: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]
[2024-05-31 07:43:59,166][func.train][INFO] - [DATASET] train size: 55183
[2024-05-31 07:43:59,166][func.train][INFO] - [DATASET] train video_indices: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]
[2024-05-31 07:43:59,171][func.train][INFO] - [DATASET] Sampling video_idx: 1 at 1 fps to 6388 frames
[2024-05-31 07:43:59,177][func.train][INFO] - [DATASET] video 1 label_list: torch.Size([6388])
[2024-05-31 07:43:59,694][func.train][INFO] - [DATASET] Sampling video_idx: 2 at 1 fps to 3620 frames
[2024-05-31 07:43:59,696][func.train][INFO] - [DATASET] video 2 label_list: torch.Size([3620])
[2024-05-31 07:43:59,751][func.train][INFO] - [DATASET] Sampling video_idx: 3 at 1 fps to 3000 frames
[2024-05-31 07:43:59,752][func.train][INFO] - [DATASET] video 3 label_list: torch.Size([3000])
[2024-05-31 07:43:59,788][func.train][INFO] - [DATASET] Sampling video_idx: 4 at 1 fps to 2938 frames
[2024-05-31 07:43:59,789][func.train][INFO] - [DATASET] video 4 label_list: torch.Size([2938])
[2024-05-31 07:43:59,835][func.train][INFO] - [DATASET] Sampling video_idx: 5 at 1 fps to 3220 frames
[2024-05-31 07:43:59,836][func.train][INFO] - [DATASET] video 5 label_list: torch.Size([3220])
[2024-05-31 07:43:59,881][func.train][INFO] - [DATASET] Sampling video_idx: 6 at 1 fps to 3908 frames
[2024-05-31 07:43:59,883][func.train][INFO] - [DATASET] video 6 label_list: torch.Size([3908])
[2024-05-31 07:43:59,934][func.train][INFO] - [DATASET] Sampling video_idx: 7 at 1 fps to 1645 frames
[2024-05-31 07:43:59,935][func.train][INFO] - [DATASET] video 7 label_list: torch.Size([1645])
[2024-05-31 07:43:59,962][func.train][INFO] - [DATASET] Sampling video_idx: 8 at 1 fps to 4692 frames
[2024-05-31 07:43:59,964][func.train][INFO] - [DATASET] video 8 label_list: torch.Size([4692])
[2024-05-31 07:44:00,021][func.train][INFO] - [DATASET] Sampling video_idx: 9 at 1 fps to 5736 frames
[2024-05-31 07:44:00,024][func.train][INFO] - [DATASET] video 9 label_list: torch.Size([5736])
[2024-05-31 07:44:00,093][func.train][INFO] - [DATASET] Sampling video_idx: 10 at 1 fps to 5064 frames
[2024-05-31 07:44:00,095][func.train][INFO] - [DATASET] video 10 label_list: torch.Size([5064])
[2024-05-31 07:44:00,158][func.train][INFO] - [DATASET] Sampling video_idx: 11 at 1 fps to 4720 frames
[2024-05-31 07:44:00,160][func.train][INFO] - [DATASET] video 11 label_list: torch.Size([4720])
[2024-05-31 07:44:00,217][func.train][INFO] - [DATASET] Sampling video_idx: 12 at 1 fps to 2916 frames
[2024-05-31 07:44:00,218][func.train][INFO] - [DATASET] video 12 label_list: torch.Size([2916])
[2024-05-31 07:44:00,240][func.train][INFO] - [DATASET] Sampling video_idx: 13 at 1 fps to 2597 frames
[2024-05-31 07:44:00,241][func.train][INFO] - [DATASET] video 13 label_list: torch.Size([2597])
[2024-05-31 07:44:00,273][func.train][INFO] - [DATASET] Sampling video_idx: 14 at 1 fps to 4739 frames
[2024-05-31 07:44:00,274][func.train][INFO] - [DATASET] video 14 label_list: torch.Size([4739])
[2024-05-31 07:44:00,322][func.train][INFO] - [DATASET] number of train videos: 14
[2024-05-31 07:44:00,322][func.train][INFO] - [DATASET] avg video length: 65.69 minutes
[2024-05-31 07:44:00,560][func.train][INFO] - [DATASET] classes_counts_dict: {0: 1408, 1: 19287, 2: 12545, 3: 7511, 4: 1333, 5: 8184, 6: 4915}
[2024-05-31 07:44:00,563][func.train][INFO] - [DATASET] curr_class_weights: tensor([5.5989, 0.4087, 0.6284, 1.0496, 5.9139, 0.9633, 1.6039])
[2024-05-31 07:44:00,563][func.train][INFO] - [DATASET] eos_weight: count
[2024-05-31 07:44:00,563][func.train][INFO] - [DATASET] num_eos_vals: 15120
[2024-05-31 07:44:00,563][func.train][INFO] - [DATASET] classes_counts_dict: {0: 1408, 1: 19287, 2: 12545, 3: 7511, 4: 1333, 5: 8184, 6: 4915, 7: 15120}
[2024-05-31 07:44:00,564][func.train][INFO] - [DATASET] next_class_weights: tensor([6.2414, 0.4556, 0.7005, 1.1700, 6.5926, 1.0738, 1.7880, 0.5812])
[2024-05-31 07:44:00,647][func.train][INFO] - [DATASET] df unique videos: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21]
[2024-05-31 07:44:00,647][func.train][INFO] - [DATASET] split: test video_indices: [15]
[2024-05-31 07:44:00,653][func.train][INFO] - [DATASET] test size: 3653
[2024-05-31 07:44:00,653][func.train][INFO] - [DATASET] test video_indices: [15]
[2024-05-31 07:44:00,657][func.train][INFO] - [DATASET] Sampling video_idx: 15 at 1 fps to 3653 frames
[2024-05-31 07:44:00,659][func.train][INFO] - [DATASET] video 15 label_list: torch.Size([3653])
[2024-05-31 07:44:00,711][func.train][INFO] - [DATASET] number of test videos: 1
[2024-05-31 07:44:00,712][func.train][INFO] - [DATASET] avg video length: 60.88 minutes
[2024-05-31 07:44:00,880][func.train][INFO] - [DATASET] df unique videos: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21]
[2024-05-31 07:44:00,881][func.train][INFO] - [DATASET] split: test video_indices: [16]
[2024-05-31 07:44:00,886][func.train][INFO] - [DATASET] test size: 3612
[2024-05-31 07:44:00,887][func.train][INFO] - [DATASET] test video_indices: [16]
[2024-05-31 07:44:00,891][func.train][INFO] - [DATASET] Sampling video_idx: 16 at 1 fps to 3612 frames
[2024-05-31 07:44:00,892][func.train][INFO] - [DATASET] video 16 label_list: torch.Size([3612])
[2024-05-31 07:44:00,941][func.train][INFO] - [DATASET] number of test videos: 1
[2024-05-31 07:44:00,942][func.train][INFO] - [DATASET] avg video length: 60.20 minutes
[2024-05-31 07:44:01,054][func.train][INFO] - [DATASET] df unique videos: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21]
[2024-05-31 07:44:01,054][func.train][INFO] - [DATASET] split: test video_indices: [17]
[2024-05-31 07:44:01,059][func.train][INFO] - [DATASET] test size: 4678
[2024-05-31 07:44:01,059][func.train][INFO] - [DATASET] test video_indices: [17]
[2024-05-31 07:44:01,063][func.train][INFO] - [DATASET] Sampling video_idx: 17 at 1 fps to 4678 frames
[2024-05-31 07:44:01,064][func.train][INFO] - [DATASET] video 17 label_list: torch.Size([4678])
[2024-05-31 07:44:01,135][func.train][INFO] - [DATASET] number of test videos: 1
[2024-05-31 07:44:01,135][func.train][INFO] - [DATASET] avg video length: 77.97 minutes
[2024-05-31 07:44:01,260][func.train][INFO] - [DATASET] df unique videos: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21]
[2024-05-31 07:44:01,261][func.train][INFO] - [DATASET] split: test video_indices: [18]
[2024-05-31 07:44:01,265][func.train][INFO] - [DATASET] test size: 3546
[2024-05-31 07:44:01,265][func.train][INFO] - [DATASET] test video_indices: [18]
[2024-05-31 07:44:01,268][func.train][INFO] - [DATASET] Sampling video_idx: 18 at 1 fps to 3546 frames
[2024-05-31 07:44:01,269][func.train][INFO] - [DATASET] video 18 label_list: torch.Size([3546])
[2024-05-31 07:44:01,332][func.train][INFO] - [DATASET] number of test videos: 1
[2024-05-31 07:44:01,333][func.train][INFO] - [DATASET] avg video length: 59.10 minutes
[2024-05-31 07:44:01,485][func.train][INFO] - [DATASET] df unique videos: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21]
[2024-05-31 07:44:01,486][func.train][INFO] - [DATASET] split: test video_indices: [19]
[2024-05-31 07:44:01,495][func.train][INFO] - [DATASET] test size: 3413
[2024-05-31 07:44:01,496][func.train][INFO] - [DATASET] test video_indices: [19]
[2024-05-31 07:44:01,504][func.train][INFO] - [DATASET] Sampling video_idx: 19 at 1 fps to 3413 frames
[2024-05-31 07:44:01,507][func.train][INFO] - [DATASET] video 19 label_list: torch.Size([3413])
[2024-05-31 07:44:01,556][func.train][INFO] - [DATASET] number of test videos: 1
[2024-05-31 07:44:01,556][func.train][INFO] - [DATASET] avg video length: 56.88 minutes
[2024-05-31 07:44:01,771][func.train][INFO] - [DATASET] df unique videos: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21]
[2024-05-31 07:44:01,772][func.train][INFO] - [DATASET] split: test video_indices: [20]
[2024-05-31 07:44:01,779][func.train][INFO] - [DATASET] test size: 4832
[2024-05-31 07:44:01,779][func.train][INFO] - [DATASET] test video_indices: [20]
[2024-05-31 07:44:01,784][func.train][INFO] - [DATASET] Sampling video_idx: 20 at 1 fps to 4832 frames
[2024-05-31 07:44:01,787][func.train][INFO] - [DATASET] video 20 label_list: torch.Size([4832])
[2024-05-31 07:44:01,849][func.train][INFO] - [DATASET] number of test videos: 1
[2024-05-31 07:44:01,850][func.train][INFO] - [DATASET] avg video length: 80.53 minutes
[2024-05-31 07:44:01,983][func.train][INFO] - [DATASET] df unique videos: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21]
[2024-05-31 07:44:01,984][func.train][INFO] - [DATASET] split: test video_indices: [21]
[2024-05-31 07:44:01,989][func.train][INFO] - [DATASET] test size: 4326
[2024-05-31 07:44:01,989][func.train][INFO] - [DATASET] test video_indices: [21]
[2024-05-31 07:44:01,993][func.train][INFO] - [DATASET] Sampling video_idx: 21 at 1 fps to 4326 frames
[2024-05-31 07:44:01,995][func.train][INFO] - [DATASET] video 21 label_list: torch.Size([4326])
[2024-05-31 07:44:02,068][func.train][INFO] - [DATASET] number of test videos: 1
[2024-05-31 07:44:02,069][func.train][INFO] - [DATASET] avg video length: 72.10 minutes
[2024-05-31 07:44:02,121][func.train][INFO] - Time to load datasets: 0.06 min
[2024-05-31 07:44:02,122][func.train][INFO] - Creating data loaders
[2024-05-31 07:44:02,124][func.train][INFO] - Creating model with {'one': 7} classes
[2024-06-01 00:25:32,581][func.train][INFO] - Dist info:
[2024-06-01 00:25:32,582][func.train][INFO] - torch version: 2.2.2+cu121
[2024-06-01 00:25:32,583][func.train][INFO] - torchvision version: 0.17.2+cu121
[2024-06-01 00:25:32,583][func.train][INFO] - hydra version: 1.3.2
[2024-06-01 00:25:32,590][func.train][INFO] - Loading data
[2024-06-01 00:25:32,590][func.train][INFO] - Loading datasets
[2024-06-01 00:25:33,050][func.train][INFO] - [SELECT DATASET] ALL loaded dataframe in 0m 0s
[2024-06-01 00:25:33,051][func.train][INFO] - [SELECT DATASET] ALL loaded dataframe: (83243, 4)
[2024-06-01 00:25:33,066][func.train][INFO] - [SELECT DATASET] labels are already starting from 0
[2024-06-01 00:25:33,090][func.train][INFO] - [SELECT DATASET] ALL unique classes: [0 1 2 3 4 5 6]
[2024-06-01 00:25:33,101][func.train][INFO] - [SELECT DATASET] aLL dataframe (head):                                           image_path  video_idx frame_idx class
0  /nfs/home/yangliu/dataset/AutoLaparo_Task1/Aut...          1         1     1
1  /nfs/home/yangliu/dataset/AutoLaparo_Task1/Aut...          1         2     1
2  /nfs/home/yangliu/dataset/AutoLaparo_Task1/Aut...          1         3     1
3  /nfs/home/yangliu/dataset/AutoLaparo_Task1/Aut...          1         4     1
4  /nfs/home/yangliu/dataset/AutoLaparo_Task1/Aut...          1         5     1
[2024-06-01 00:25:33,111][func.train][INFO] - [SELECT DATASET] ALL dataframe (tail):                                               image_path  ...  class
83238  /nfs/home/yangliu/dataset/AutoLaparo_Task1/Aut...  ...      6
83239  /nfs/home/yangliu/dataset/AutoLaparo_Task1/Aut...  ...      6
83240  /nfs/home/yangliu/dataset/AutoLaparo_Task1/Aut...  ...      6
83241  /nfs/home/yangliu/dataset/AutoLaparo_Task1/Aut...  ...      6
83242  /nfs/home/yangliu/dataset/AutoLaparo_Task1/Aut...  ...      6

[5 rows x 4 columns]
[2024-06-01 00:25:33,112][func.train][INFO] - [DATASET] params: {'debug': False, 'dataset_name': 'autolaparo21', 'reduc_feats_folder': 'train_targets_x_mp/', 'num_classes': 7, 'num_next_labels': 6, 'last_seg_class': 7, 'predict_next_phase': True, 'get_target_feats': False, 'replace_current_with_next_class': False}
[2024-06-01 00:25:33,184][func.train][INFO] - [DATASET] df unique videos: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21]
[2024-06-01 00:25:33,184][func.train][INFO] - [DATASET] split: train video_indices: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]
[2024-06-01 00:25:33,221][func.train][INFO] - [DATASET] train size: 55183
[2024-06-01 00:25:33,221][func.train][INFO] - [DATASET] train video_indices: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]
[2024-06-01 00:25:33,225][func.train][INFO] - [DATASET] Sampling video_idx: 1 at 1 fps to 6388 frames
[2024-06-01 00:25:33,229][func.train][INFO] - [DATASET] video 1 label_list: torch.Size([6388])
[2024-06-01 00:25:33,918][func.train][INFO] - [DATASET] Sampling video_idx: 2 at 1 fps to 3620 frames
[2024-06-01 00:25:33,925][func.train][INFO] - [DATASET] video 2 label_list: torch.Size([3620])
[2024-06-01 00:25:34,023][func.train][INFO] - [DATASET] Sampling video_idx: 3 at 1 fps to 3000 frames
[2024-06-01 00:25:34,026][func.train][INFO] - [DATASET] video 3 label_list: torch.Size([3000])
[2024-06-01 00:25:34,086][func.train][INFO] - [DATASET] Sampling video_idx: 4 at 1 fps to 2938 frames
[2024-06-01 00:25:34,088][func.train][INFO] - [DATASET] video 4 label_list: torch.Size([2938])
[2024-06-01 00:25:34,160][func.train][INFO] - [DATASET] Sampling video_idx: 5 at 1 fps to 3220 frames
[2024-06-01 00:25:34,162][func.train][INFO] - [DATASET] video 5 label_list: torch.Size([3220])
[2024-06-01 00:25:34,238][func.train][INFO] - [DATASET] Sampling video_idx: 6 at 1 fps to 3908 frames
[2024-06-01 00:25:34,241][func.train][INFO] - [DATASET] video 6 label_list: torch.Size([3908])
[2024-06-01 00:25:34,341][func.train][INFO] - [DATASET] Sampling video_idx: 7 at 1 fps to 1645 frames
[2024-06-01 00:25:34,343][func.train][INFO] - [DATASET] video 7 label_list: torch.Size([1645])
[2024-06-01 00:25:34,388][func.train][INFO] - [DATASET] Sampling video_idx: 8 at 1 fps to 4692 frames
[2024-06-01 00:25:34,391][func.train][INFO] - [DATASET] video 8 label_list: torch.Size([4692])
[2024-06-01 00:25:34,506][func.train][INFO] - [DATASET] Sampling video_idx: 9 at 1 fps to 5736 frames
[2024-06-01 00:25:34,510][func.train][INFO] - [DATASET] video 9 label_list: torch.Size([5736])
[2024-06-01 00:25:34,676][func.train][INFO] - [DATASET] Sampling video_idx: 10 at 1 fps to 5064 frames
[2024-06-01 00:25:34,679][func.train][INFO] - [DATASET] video 10 label_list: torch.Size([5064])
[2024-06-01 00:25:34,800][func.train][INFO] - [DATASET] Sampling video_idx: 11 at 1 fps to 4720 frames
[2024-06-01 00:25:34,803][func.train][INFO] - [DATASET] video 11 label_list: torch.Size([4720])
[2024-06-01 00:25:34,912][func.train][INFO] - [DATASET] Sampling video_idx: 12 at 1 fps to 2916 frames
[2024-06-01 00:25:34,914][func.train][INFO] - [DATASET] video 12 label_list: torch.Size([2916])
[2024-06-01 00:25:34,969][func.train][INFO] - [DATASET] Sampling video_idx: 13 at 1 fps to 2597 frames
[2024-06-01 00:25:34,971][func.train][INFO] - [DATASET] video 13 label_list: torch.Size([2597])
[2024-06-01 00:25:35,024][func.train][INFO] - [DATASET] Sampling video_idx: 14 at 1 fps to 4739 frames
[2024-06-01 00:25:35,027][func.train][INFO] - [DATASET] video 14 label_list: torch.Size([4739])
[2024-06-01 00:25:35,095][func.train][INFO] - [DATASET] number of train videos: 14
[2024-06-01 00:25:35,096][func.train][INFO] - [DATASET] avg video length: 65.69 minutes
[2024-06-01 00:25:35,153][func.train][INFO] - [DATASET] num classes at 1fps in train: (55183,)
[2024-06-01 00:25:35,156][func.train][INFO] - [DATASET] classes_counts_dict: {0: 1408, 1: 19287, 2: 12545, 3: 7511, 4: 1333, 5: 8184, 6: 4915}
[2024-06-01 00:25:35,163][func.train][INFO] - [DATASET] curr_class_weights: tensor([5.5989, 0.4087, 0.6284, 1.0496, 5.9139, 0.9633, 1.6039])
[2024-06-01 00:25:35,164][func.train][INFO] - [DATASET] eos_weight: count
[2024-06-01 00:25:35,164][func.train][INFO] - [DATASET] num_eos_vals: 15120
[2024-06-01 00:25:35,165][func.train][INFO] - [DATASET] classes_counts_dict: {0: 1408, 1: 19287, 2: 12545, 3: 7511, 4: 1333, 5: 8184, 6: 4915, 7: 15120}
[2024-06-01 00:25:35,167][func.train][INFO] - [DATASET] next_class_weights: tensor([6.2414, 0.4556, 0.7005, 1.1700, 6.5926, 1.0738, 1.7880, 0.5812])
[2024-06-01 00:25:35,357][func.train][INFO] - [DATASET] df unique videos: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21]
[2024-06-01 00:25:35,358][func.train][INFO] - [DATASET] split: test video_indices: [15]
[2024-06-01 00:25:35,370][func.train][INFO] - [DATASET] test size: 3653
[2024-06-01 00:25:35,371][func.train][INFO] - [DATASET] test video_indices: [15]
[2024-06-01 00:25:35,378][func.train][INFO] - [DATASET] Sampling video_idx: 15 at 1 fps to 3653 frames
[2024-06-01 00:25:35,382][func.train][INFO] - [DATASET] video 15 label_list: torch.Size([3653])
[2024-06-01 00:25:35,447][func.train][INFO] - [DATASET] number of test videos: 1
[2024-06-01 00:25:35,448][func.train][INFO] - [DATASET] avg video length: 60.88 minutes
[2024-06-01 00:25:35,550][func.train][INFO] - [DATASET] df unique videos: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21]
[2024-06-01 00:25:35,551][func.train][INFO] - [DATASET] split: test video_indices: [16]
[2024-06-01 00:25:35,561][func.train][INFO] - [DATASET] test size: 3612
[2024-06-01 00:25:35,562][func.train][INFO] - [DATASET] test video_indices: [16]
[2024-06-01 00:25:35,570][func.train][INFO] - [DATASET] Sampling video_idx: 16 at 1 fps to 3612 frames
[2024-06-01 00:25:35,572][func.train][INFO] - [DATASET] video 16 label_list: torch.Size([3612])
[2024-06-01 00:25:35,651][func.train][INFO] - [DATASET] number of test videos: 1
[2024-06-01 00:25:35,652][func.train][INFO] - [DATASET] avg video length: 60.20 minutes
[2024-06-01 00:25:35,749][func.train][INFO] - [DATASET] df unique videos: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21]
[2024-06-01 00:25:35,750][func.train][INFO] - [DATASET] split: test video_indices: [17]
[2024-06-01 00:25:35,761][func.train][INFO] - [DATASET] test size: 4678
[2024-06-01 00:25:35,762][func.train][INFO] - [DATASET] test video_indices: [17]
[2024-06-01 00:25:35,770][func.train][INFO] - [DATASET] Sampling video_idx: 17 at 1 fps to 4678 frames
[2024-06-01 00:25:35,773][func.train][INFO] - [DATASET] video 17 label_list: torch.Size([4678])
[2024-06-01 00:25:35,880][func.train][INFO] - [DATASET] number of test videos: 1
[2024-06-01 00:25:35,883][func.train][INFO] - [DATASET] avg video length: 77.97 minutes
[2024-06-01 00:25:36,116][func.train][INFO] - [DATASET] df unique videos: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21]
[2024-06-01 00:25:36,117][func.train][INFO] - [DATASET] split: test video_indices: [18]
[2024-06-01 00:25:36,132][func.train][INFO] - [DATASET] test size: 3546
[2024-06-01 00:25:36,133][func.train][INFO] - [DATASET] test video_indices: [18]
[2024-06-01 00:25:36,205][func.train][INFO] - [DATASET] Sampling video_idx: 18 at 1 fps to 3546 frames
[2024-06-01 00:25:36,208][func.train][INFO] - [DATASET] video 18 label_list: torch.Size([3546])
[2024-06-01 00:25:36,295][func.train][INFO] - [DATASET] number of test videos: 1
[2024-06-01 00:25:36,296][func.train][INFO] - [DATASET] avg video length: 59.10 minutes
[2024-06-01 00:25:36,392][func.train][INFO] - [DATASET] df unique videos: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21]
[2024-06-01 00:25:36,393][func.train][INFO] - [DATASET] split: test video_indices: [19]
[2024-06-01 00:25:36,401][func.train][INFO] - [DATASET] test size: 3413
[2024-06-01 00:25:36,402][func.train][INFO] - [DATASET] test video_indices: [19]
[2024-06-01 00:25:36,409][func.train][INFO] - [DATASET] Sampling video_idx: 19 at 1 fps to 3413 frames
[2024-06-01 00:25:36,411][func.train][INFO] - [DATASET] video 19 label_list: torch.Size([3413])
[2024-06-01 00:25:36,510][func.train][INFO] - [DATASET] number of test videos: 1
[2024-06-01 00:25:36,511][func.train][INFO] - [DATASET] avg video length: 56.88 minutes
[2024-06-01 00:25:36,607][func.train][INFO] - [DATASET] df unique videos: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21]
[2024-06-01 00:25:36,608][func.train][INFO] - [DATASET] split: test video_indices: [20]
[2024-06-01 00:25:36,618][func.train][INFO] - [DATASET] test size: 4832
[2024-06-01 00:25:36,618][func.train][INFO] - [DATASET] test video_indices: [20]
[2024-06-01 00:25:36,627][func.train][INFO] - [DATASET] Sampling video_idx: 20 at 1 fps to 4832 frames
[2024-06-01 00:25:36,629][func.train][INFO] - [DATASET] video 20 label_list: torch.Size([4832])
[2024-06-01 00:25:36,756][func.train][INFO] - [DATASET] number of test videos: 1
[2024-06-01 00:25:36,758][func.train][INFO] - [DATASET] avg video length: 80.53 minutes
[2024-06-01 00:25:36,859][func.train][INFO] - [DATASET] df unique videos: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21]
[2024-06-01 00:25:36,860][func.train][INFO] - [DATASET] split: test video_indices: [21]
[2024-06-01 00:25:36,871][func.train][INFO] - [DATASET] test size: 4326
[2024-06-01 00:25:36,871][func.train][INFO] - [DATASET] test video_indices: [21]
[2024-06-01 00:25:36,880][func.train][INFO] - [DATASET] Sampling video_idx: 21 at 1 fps to 4326 frames
[2024-06-01 00:25:36,883][func.train][INFO] - [DATASET] video 21 label_list: torch.Size([4326])
[2024-06-01 00:25:37,021][func.train][INFO] - [DATASET] number of test videos: 1
[2024-06-01 00:25:37,024][func.train][INFO] - [DATASET] avg video length: 72.10 minutes
[2024-06-01 00:25:37,038][func.train][INFO] - Time to load datasets: 0.07 min
[2024-06-01 00:25:37,040][func.train][INFO] - Creating data loaders
[2024-06-01 00:25:37,056][func.train][INFO] - Creating model with {'one': 7} classes
[2024-06-01 00:25:38,834][func.train][INFO] - [MAIN] Number of tokens: 55183
[2024-06-01 00:25:38,835][func.train][INFO] - [MAIN] Number of parameters: 18026710
[2024-06-01 00:25:38,836][func.train][INFO] - [MAIN] Token-to-Parameter Ratio is ideally between [1:1 to 10:1]: 0.003061
[2024-06-01 00:25:38,837][func.train][WARNING] - [MAIN] Data-to-Parameter-Ratio is outside the interval [1:1 to 10:1]
[2024-06-01 00:25:38,839][func.train][INFO] - Using LR 0.000300 WD 0.000010 for parameters
[2024-06-01 00:25:38,840][func.train][INFO] - Using LR 0.000300 WD 0.000010 for parameters
[2024-06-01 00:25:38,859][func.train][INFO] - Wrapping model into DP
[2024-06-01 00:25:39,225][func.train][INFO] - Start training
[2024-06-01 00:25:39,233][func.train][INFO] - Storing checkpoints every 60.00 mins
